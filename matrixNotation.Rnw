\documentclass{article}
\usepackage{fullpage}
\begin{document}

<<>>=
set.seed(20151001)
library(testthat)
@ 

\section*{Goal and running example}
Let $X$ be a (model) matrix of covariates with dimension $n \times p$. Any missing values have been imputed. Let $M$ be a matrix of missingness indicators with dimension $n \times p$ (this varies from our previous missingness indicators that will only have a column for each variable that is missing. We need to expand to get the matrix ops to work out. Also, since the we've already done model matrix expansion, we'll need a matrix that corresponds to missingness in the original variable, so many columns many be indentical as they represent the same categorical variable). $C$ is a $n \times c$ (sparse) matrix indicating cluster membership with 1, zero otherwise for $c$ clusters. $S$ is a $n \times s$ (sparse) matrix indicating membership in the $s$ strata. While each row of $C$ has one and only one finite entry, it may be the case that some units are not in any stratum. $Z$ is a vector of treatment assignment. We can assume it has been validated that all members of the same cluster have the same $Z_i$ value and all clusters are nested within strata. Furthermore, all strata have at least one treated and at least one control (if not we set members of those strata to zero everywhere).

Goal: express all operations required for \texttt{xBalance} computations with respect to these matrices.


Some examples to check that we get what we want. 2 sets of 3 and one
set of 2. We'll use column matrices to make sure we have the right
dimensions everywhere. We'll make group~3's treated unit missing a value on
$X_1$ (but not other $X$), both of group~2's treated units missing on
$X_2$ but not other $X$es, and both of group~1's control units missing on $X_3$. 
Nothing missing on $X_4$.  
<<>>=
X <- matrix(rnorm(32), nrow = 8)
colnames(X) <- paste0("X", 1:4)

Z <- c(1,0,0,1,1,0,0,1) 
S <- matrix(c(rep(c(1,0,0), 3), rep(c(0,1,0), 3), rep(c(0,0,1), 2)), nrow = 8, byrow = T)
colnames(S) <- letters[1:3]
cbind("Z"=Z, S)

missing <- matrix(c(0,0,0,0,0,0,0,1, # X_1
               0,0,0,1,1,0,0,0, # X_2
               0,1,1,0,0,0,0,0, # X_3
               0,0,0,0,0,0,0,0),# X_4
             nrow = 8)
colnames(missing) <- colnames(X)
NotMissing <- 0 + !missing #we prefer a numeric matrix, 
NotMissing                 #for upcoming generalizations
@ 

\section*{Strata but no case weights or clusters}

\subsection*{Means \& mean differences}

For each variable we want to drop any units in
strata that have all missing treated or all missing control. 

<<>>=
ZZ <- S * Z# this matrix indicates which units are treated, by stratum
S.missing.1s <- t(ZZ) %*% NotMissing ==0 # result is s * p
S.missing.0s <- t(S * !Z ) %*% NotMissing == 0# s * p also
( S.has.both <- 0 + # again we prefer a numeric to a logical matrix
     !(S.missing.0s | S.missing.1s)  # coercion to logical treats pos values as TRUE
 )
@ 

At the end of the day, we want a matrix that is $n \times p$, where $p$ is
the number of variables we're considering.
<<>>=
use.units <- (S %*% S.has.both) # n * p
use.units <- use.units * NotMissing
@ 


Counts of non-missing observations, separately for treatment
and control:
<<>>=
n1 <- t(use.units) %*% Z # p * 1
n0 <- t(use.units) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 


Deal with missing values.
<<>>=

X.use  <- X * use.units

@ 

Means of non-missing observations in the treatment group.
<<>>=
treated.avg <- t(X.use) %*% Z / n1 # p * 1

@ 

Which is basically the same as what \texttt{mean(\ldots, na.rm=T)} would
have delivered:
<<>>=

zapsmall(treated.avg -
    apply(ifelse(NotMissing * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          )
         )==0


@ 
The discrepancy for \texttt{X3} being caused by its lacking \textit{control}
group observations in stratum a, which for this reason gets dropped
from the calculation:
 
<<>>=
S.missing.1s

expect_true(all( abs(treated.avg -
    apply(ifelse(use.units * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          ))<=.Machine$double.eps^.5
         ) )

@ 

To determine a weighting scheme with which to prepare corresponding
control group  averages, we can use the treatment group
as the standard population, so that the contributions from a given
stratum are up-or down-weighted in proportion to the fraction of the
stratum assigned to treatment.   We'll refer to this as ``ETT weighting.''
 Here are the ETT weights, by stratum and variable: 
<<>>=
t(ZZ) %*% use.units
@
Note that strata which don't admit of a
comparison are implicitly dropped, due to the \texttt{S.has.both}
factor in the earlier calculation of \texttt{use.units}.

Although these weights attach to the stratum rather than
the case, our present reference implementation 
uses the name \texttt{ETT} for the case by variable
representation of them: 
<<>>=
ETT <- S %*%  (t(ZZ) %*% use.units )   # n * p
@ 

So the ETT-weighted averages of the control group are
<<>>=
n0.ett <- t( use.units * ETT ) %*%  (1 - Z) 
(control.avg <- t(X.use * ETT ) %*% (1 - Z) / n0.ett)
@ 

\subsection*{Scale \& scaled mean differences}
Next up, pooled standard deviations.  \textbf{NB: \texttt{var.0} is broken,
please fix!}

<<>>=
X2.use <- X^2 * use.units # same exclusions as w/ X1.use
var.1 <- t(X2.use) %*% Z - n1 * treated.avg^2
var.0 <- t(X2.use * ETT) %*% (1 - Z) - n0 * control.avg^2

(pooled <- sqrt((var.1 + var.0) / (n1 + n0 - 2)))
apply(ifelse(use.units, 
             X, NA_real_), 
      2, function(var) summary(lm(var~Z))$sigma )
@


The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 

\section*{Enhancement: unify pruning of strata \& weighting by stratum}

The operations of stratum weighting (``ETT'') and kicking out strata
that don't admit of a comparison should be unified.  This will
simplify the calculations and make it easier to create a slot for
alternate weighting schemes.\ldots


\section*{Strata and case weights}

Although the header doesn't say anything about clusters, the intention
is that these adaptations will address those also, by dint of the following.

\begin{quote}
  \textit{Assumptions.}  If the user specified a clustering variable
  alongside of an element-by-variable table (and potentially element
  weights), then that data frame 
  has already been processed into cluster-by-variable matrices
  \texttt{X} and \texttt{pv.c.wt}. Furthermore
  \begin{enumerate}
  \item \label{item:1} Each \texttt{X} entry represents a weighted \textit{mean}
    over the non-missing values of the variable for the cluster in
    question, with weights equal to user-provided element weights. 
  \item Each \texttt{pv.c.wt} entry records a \textit{sum} of
    user-provided element
    weights, over elements within the cluster for which the variable
    was not missing.
  \end{enumerate}
\end{quote}
(\ref{item:1} might equally well have used weighted sums as opposed to
weighted means. I favor this convention mostly for future-proofing: we
may at some point wish to enable merges of cluster-level data frames
with Design objects we've aggregated from element to cluster level.)

\subsection*{Means \& mean differences}
We need to make \emph{per-variable} case weights,
``\texttt{pv.c.wt},'' products of user-provided case weights (implicit
$1$'s when the user hasn't specified a weight) and per-variable
missingness indicators. 

<<>>=
case.weights <- rep(1,8) # for now
pv.c.wt <- use.units * case.weights
@ 

This time the moment calculations begin as follows.% reorganize this for coherence
                                      %w/ subsequent blocks?

<<>>=

X.use  <- X * pv.c.wt
X2.use <- X * X.use

@ 
Note that \texttt{pv.c.wt} is doing two things here, imposing case
weights on a per-variable basis plus zeroing out the missing entries.
We'll do the same thing to calculate ``\texttt{n1}'' and
``\texttt{n0}.''   This is now an abuse of notation, however, since
they're not sample sizes but per variable sums of case weights:
<<>>=
n1 <- t(pv.c.wt) %*% Z # p * 1
n0 <- t(pv.c.wt) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 
(When we start with constant case weights, \texttt{n1} differences across variables are
due entirely to differences in missingness patterns [and similarly for
\texttt{n0}].)

To compute weighted means over the 
treatment group, applying case weights
and downweighting missing items to 0 
(but with no adjustment for strata), do:
<<>>=
(treated.avg <- t(X.use) %*% Z / n1) # p * 1
@ 

ETT weights (by case and variable) are computed as follows.
<<>>=
(ETT <- S %*% t(ZZ) %*% pv.c.wt) # n * p
@ 

Now weighted averages of the control group, using the weighted
treatment group as a standard population, are computed by:
<<>>=
n0.ett <- t(ETT) %*% (1 - Z)
(control.avg <- t(X * ETT) %*% (1 - Z) / n0.ett)
@ 

\subsection*{Scale \& scaled mean differences}
Next up, pooled standard deviations. 

<<>>=

var.1 <- t(X2.use) %*% Z - n1 * treated.avg^2
var.0 <- t(X2.use) %*% (1 - Z) - n0 * control.avg^2

(pooled <- sqrt((var.1 + var.0) / (n1 + n0 - 2)))
apply(X.use, 2, function(i) { sd(i[i != 0]) }) # in general this would not work; but we know that exactly zero means missing in this data set.
@

Pretty close. Good. We wouldn't expect them to be identical. 

The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 

\end{document}
