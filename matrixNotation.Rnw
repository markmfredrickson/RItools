\documentclass{article}
\usepackage{fullpage}
\begin{document}

<<>>=
set.seed(20151001)
library(testthat)
@ 

\section*{Goal and running example}
Let $X$ be a (model) matrix of covariates with dimension $n \times p$. Any missing values have been imputed. Let $M$ be a matrix of missingness indicators with dimension $n \times p$ (this varies from our previous missingness indicators that will only have a column for each variable that is missing. We need to expand to get the matrix ops to work out. Also, since the we've already done model matrix expansion, we'll need a matrix that corresponds to missingness in the original variable, so many columns many be indentical as they represent the same categorical variable). $C$ is a $n \times c$ (sparse) matrix indicating cluster membership with 1, zero otherwise for $c$ clusters. $S$ is a $n \times s$ (sparse) matrix indicating membership in the $s$ strata. While each row of $C$ has one and only one finite entry, it may be the case that some units are not in any stratum. $Z$ is a vector of treatment assignment. We can assume it has been validated that all members of the same cluster have the same $Z_i$ value and all clusters are nested within strata. Furthermore, all strata have at least one treated and at least one control (if not we set members of those strata to zero everywhere).

Goal: express all operations required for \texttt{xBalance} computations with respect to these matrices.


Some examples to check that we get what we want. 2 sets of 3 and one
set of 2. We'll use column matrices to make sure we have the right
dimensions everywhere. We'll make group~3's treated unit missing a value on
$X_1$ (but not other $X$), both of group~2's treated units missing on
$X_2$ but not other $X$es, and both of group~1's control units missing on $X_3$. 
Nothing missing on $X_4$.  
<<>>=
X <- matrix(rnorm(32), nrow = 8)
colnames(X) <- paste0("X", 1:4)

Z <- c(1,0,0,1,1,0,0,1) 
S <- matrix(c(rep(c(1,0,0), 3), rep(c(0,1,0), 3), rep(c(0,0,1), 2)), nrow = 8, byrow = T)
colnames(S) <- letters[1:3]
cbind("Z"=Z, S)

missing <- matrix(c(0,0,0,0,0,0,0,1, # X_1
               0,0,0,1,1,0,0,0, # X_2
               0,1,1,0,0,0,0,0, # X_3
               0,0,0,0,0,0,0,0),# X_4
             nrow = 8)
colnames(missing) <- colnames(X)
NotMissing <- 0 + !missing #we prefer a numeric matrix, 
NotMissing                 #for upcoming generalizations
@ 

\section*{Strata but no element weights or clusters}

\subsection*{Means \& mean differences}

For each variable we want to drop any units in
strata that have all missing treated or all missing control. 

<<>>=

ZZ <-  S * Z # this matrix indicates which units are treated, by stratum
WW <-  S * !Z # which units are control, again by stratum 
S.missing.1s <- t(ZZ) %*% NotMissing ==0 # result is s * p
S.missing.0s <- t(WW) %*% NotMissing == 0# s * p also
( S.has.both <- 0 + # again we prefer a numeric to a logical matrix
     !(S.missing.0s | S.missing.1s)  # coercion to logical treats pos values as TRUE
 )

@ 

At the end of the day, we want a matrix that is $n \times p$, where $p$ is
the number of variables we're considering.
<<>>=
use.units <- (S %*% S.has.both) # n * p
use.units <- use.units * NotMissing
@ 


Counts of non-missing observations, separately for treatment
and control:
<<>>=
n1 <- t(use.units) %*% Z # p * 1
n0 <- t(use.units) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 


Deal with missing values.
<<>>=

X.use  <- X * use.units

@ 

Means of non-missing observations in the treatment group.
<<>>=
treated.avg <- t(X.use) %*% Z / n1 # p * 1

@ 

Which is basically the same as what \texttt{mean(\ldots, na.rm=T)} would
have delivered:
<<>>=

zapsmall(treated.avg -
    apply(ifelse(NotMissing * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          )
         )==0


@ 
The discrepancy for \texttt{X3} being caused by its lacking \textit{control}
group observations in stratum a, which for this reason gets dropped
from the calculation:
 
<<>>=
S.missing.1s

expect_true(all( abs(treated.avg -
    apply(ifelse(use.units * as.vector(Z),
               X, NA_real_),
          2, function(x) mean(x, na.rm=T)
          ))<=.Machine$double.eps^.5
         ) )

@ 


To generalize this in order to get corresponding averages for
controls, we conceptualize these weights as Horwitz-Thompson type
weights, proportional to the inverse probability of assignment; but
then we also associate weights with strata that are prortional to the
number of units assigned to treatment in that stratum. For treatment
group members, the product of these two factors is 1; for controls,
it's the ``treatment odds'' or a priori odds of assignment to
treatment.  The treatment group is in effect serving to define a standard
population. This scheme has the advantage of culminating naturally in
treatment and control group means that are each interpretable as a 
combined ratio estimates of means over that standard population.

To determine a weighting scheme with which to prepare corresponding
control group  averages, we can use the treatment group
as the standard population, so that the contributions from a given
stratum are up-or down-weighted in proportion to the fraction of the
stratum assigned to treatment.   Specifically, a weighting factor
equal to the odds of assignment to treatment is to be applied to each
control.  

Here are these factors, by stratum and variable: 
<<>>=
Z.odds <- ( t(ZZ) %*% use.units ) / ( t(WW) %*% use.units )
( Z.odds <- ifelse(S.has.both, Z.odds, 0) ) # s * p
@
Note that strata which don't admit of a
comparison have to be explicitly dropped, via \texttt{S.has.both}.

Although these weights attach to the stratum rather than
the element, an earlier reference implementation 
uses the name \texttt{ETT} (for ``effect of treatment on treated'') for the element by variable
representation of them: 
<<>>=
ETT <- S %*%  Z.odds  # n * p
@ 
(At 9a84617 this writeup fell a little behind the development w/in the
clusters branch; there weights for both treatments and controls are
calculated explicity from a combo of aggregated element weights and
stratum weights.)

So the ETT-weighted averages of the control group are
<<>>=
n0.ett <- t( use.units * ETT ) %*%  (1 - Z) 
(control.avg <- t(X.use * ETT ) %*% (1 - Z) / n0.ett)
@ 

\subsection*{Scale \& scaled mean differences}
Next up, pooled standard deviations.  

<<>>=
X2.use <- X^2 * use.units # same exclusions as w/ X1.use
var.1 <- ( t(X2.use) %*% Z - n1 * treated.avg^2 )/(n1 -1 )
var.0 <- ( t(X2.use * ETT) %*% (1 - Z) - n0.ett * control.avg^2 )/n0.ett
var.0 <- var.0 * n0/(n0-1)
@ 

Comparing to the unweighted, pooled variances calc (which isn't really
expected to give the same thing):
<<>>=

(pooled <- sqrt((var.1*(n1-1) + var.0*(n0-1)) / (n1 + n0 - 2)))
apply(ifelse(use.units, 
             X, NA_real_), 
      2, function(var) summary(lm(var~Z))$sigma )
@


The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 

\section*{Enhancement: unify pruning of strata \& weighting by stratum}

The operations of stratum weighting (``ETT'') and kicking out strata
that don't admit of a comparison should be unified.  This will
simplify the calculations and make it easier to create a slot for
alternate weighting schemes.\ldots


\section*{Strata and element weights}

Although the header doesn't say anything about clusters, the intention
is that these adaptations will address those also, by dint of the following.

\begin{quote}
  \textit{Assumptions.}  If the user specified a clustering variable
  alongside of an element-by-variable table (and potentially element
  weights), then that data frame 
  has already been processed into cluster-by-variable matrices
  \texttt{X} and \texttt{pv.c.wt}. Furthermore
  \begin{enumerate}
  \item \label{item:1} Each \texttt{X} entry represents a weighted \textit{mean}
    over the non-missing values of the variable for the cluster in
    question, with weights equal to user-provided element weights. 
  \item Each \texttt{pv.c.wt} entry records a \textit{sum} of
    user-provided element
    weights, over elements within the cluster for which the variable
    was not missing.
  \end{enumerate}
\end{quote}
(\ref{item:1} might equally well have used weighted sums as opposed to
weighted means. I favor this convention mostly for future-proofing: we
may at some point wish to enable merges of cluster-level data frames
with Design objects we've aggregated from element to cluster level.)

\subsection*{Means \& mean differences}
We need to make \emph{per-variable} element weights,
``\texttt{pv.c.wt},'' products of user-provided element weights (implicit
$1$'s when the user hasn't specified a weight) and per-variable
missingness indicators. 

<<>>=
element.weights <- rep(1,8) # for now
pv.c.wt <- use.units * element.weights
@ 

This time the moment calculations begin as follows.% reorganize this for coherence
                                      %w/ subsequent blocks?

<<>>=

X.use  <- X * pv.c.wt
X2.use <- X * X.use

@ 
Note that \texttt{pv.c.wt} is doing two things here, imposing element
weights on a per-variable basis plus zeroing out the missing entries.
We'll do the same thing to calculate ``\texttt{n1}'' and
``\texttt{n0}.''   This is now an abuse of notation, however, since
they're not sample sizes but per variable sums of element weights:
<<>>=
n1 <- t(pv.c.wt) %*% Z # p * 1
n0 <- t(pv.c.wt) %*% (1 - Z) # p * 1
t(cbind(n1, n0, n1 + n0)) # 3 * p
@ 
(When we start with constant element weights, \texttt{n1} differences across variables are
due entirely to differences in missingness patterns [and similarly for
\texttt{n0}].)

To compute weighted means over the 
treatment group, applying element weights
and downweighting missing items to 0 
(but with no adjustment for strata), do:
<<>>=
(treated.avg <- t(X.use) %*% Z / n1) # p * 1
@ 

ETT weighting factor (by element and variable) are computed as follows.
<<>>=
Z.odds <- ( t(ZZ) %*% use.units ) / ( t(WW) %*% use.units )
( Z.odds <- ifelse(S.has.both, Z.odds, 0) ) # s * p
(ETT <- S %*% Z.odds) # n * p
@ 

Notice that the element weights don't come into play yet -- this
weighting factor is separated from those weights, which on the other
hand get baked directly into \texttt{X.use}, \texttt{X2.use}.

Now weighted averages of the control group, using the weighted
treatment group as a standard population, are computed by:

<<>>=
n0.ett <- t( pv.c.wt * ETT ) %*%  (1 - Z) 
(control.avg <- t(X.use * ETT ) %*% (1 - Z) / n0.ett)
@ 

\subsection*{Scale \& scaled mean differences}

Next up, pooled standard deviations. 

<<>>=
X2.use <- X^2 * pv.c.wt # same exclusions as w/ X1.use
var.1 <- ( t(X2.use) %*% Z - n1 * treated.avg^2 )/(n1 -1 )
var.0 <- ( t(X2.use * ETT) %*% (1 - Z) - n0.ett * control.avg^2 )/n0.ett
var.0 <- var.0 * n0/(n0-1)
@ 

Comparing to the unweighted, pooled variances calc (which isn't really
expected to give the same thing):
<<>>=

(pooled <- sqrt((var.1*(n1-1) + var.0*(n0-1)) / (n1 + n0 - 2)))
apply(ifelse(use.units, 
             X, NA_real_), 
      2, function(var) summary(lm(var~Z))$sigma )
@


The standardized differences:
<<>>=
(adjustedDifferences    <- treated.avg - control.avg)
(standardizeDifferences <- adjustedDifferences / pooled)
@ 
\end{document}
